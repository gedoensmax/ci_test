# This starter workflow is for a CMake project running on multiple platforms. There is a different starter workflow if you just want a single platform.
# See: https://github.com/actions/starter-workflows/blob/main/ci/cmake-single-platform.yml
name: Run ONNX Runtime build

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build:
    runs-on: ${{ matrix.os }}

    strategy:
      # Set fail-fast to false to ensure that feedback is delivered for all matrix combinations. Consider changing this to true when your workflow is stable.
      fail-fast: false

      # Set up a matrix to run the following 3 configurations:
      # 1. <Windows, Release, latest MSVC compiler toolchain on the default runner image, default generator>
      # 2. <Linux, Release, latest GCC compiler toolchain on the default runner image, default generator>
      # 3. <Linux, Release, latest Clang compiler toolchain on the default runner image, default generator>
      #
      # To add more build types (Release, Debug, RelWithDebInfo, etc.) customize the build_type list.
      matrix:
        os: [ubuntu-latest, windows-latest ]
        build_type: [Release]
        c_compiler: [gcc, cl] #, clang]
        include:
          - os: windows-latest
            c_compiler: cl
            cpp_compiler: cl
          - os: ubuntu-latest
            c_compiler: gcc
            cpp_compiler: g++
          # - os: ubuntu-latest
          #   c_compiler: clang
          #   cpp_compiler: clang++
        exclude:
          - os: windows-latest
            c_compiler: gcc
          - os: windows-latest
            c_compiler: clang
          - os: ubuntu-latest
            c_compiler: cl

    steps:
    - uses: actions/checkout@v3
      with:
        repository: microsoft/onnxruntime
        path: onnxruntime
  
    - uses: Jimver/cuda-toolkit@v0.2.14
      id: cuda-toolkit
      with:
        cuda: '12.3.2'
        method: "network"
        # non-cuda-sub-packages: '["libcublas", "libcufft", "libcurand", "libcusparse"]'
        # sub-packages: '["nvcc", "nvtx", "cudart"]'

    - name: Install cudnn
      if: ${{ matrix.os != 'windows-latest' }}
      run: |
        sudo apt-get install -y cudnn9


    # - name: Install tensorrt
    #   if: ${{ matrix.os != 'windows-latest' }}
    #   run: |
    #     sudo apt-get update
    #     sudo apt-get install -y tensorrt

    - name: Chmod scripts
      if: ${{ matrix.os != 'windows-latest' }}
      working-directory: ./onnxruntime
      run: |
        chmod +x ./build.sh

    - name: Run build script ubuntu
      if: ${{ matrix.os != 'windows-latest' }}
      working-directory: ./onnxruntime
      run: >
        ./build.sh --use_cuda --cmake_extra_defines "CMAKE_INSTALL_PREFIX=$PWD/../ort_install" 
        --cuda_home=$CUDA_PATH --cudnn_home=$CUDA_PATH
      # --use_tensorrt --tensorrt_home=$CUDA_PATH
    
    - name: Run build script windows
      if: ${{ matrix.os == 'windows-latest' }}
      working-directory: ./onnxruntime
      run: >
        ./build.bat --cmake_extra_defines "CMAKE_INSTALL_PREFIX=$PWD/../ort_install" 
      # --use_cuda --cuda_home=$CUDA_PATH --cudnn_home=$CUDA_PATH
      # --use_tensorrt --tensorrt_home=$CUDA_PATH
    
        
    - name: Archive ORT install folder
      uses: actions/upload-artifact@v4
      with:
        name: ort_install-${{ matrix.os }}
        path: |
          ort_install
          
